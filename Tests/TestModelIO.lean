/-
  Tests/TestModelIO.lean

  Tests for Model Parameter serialization and structure traversal using TensorStruct.
-/
import Tyr
import Examples.NanoChat.ModdedGPT
import LeanTest

/-!
# `Tests.TestModelIO`

Model IO regressions for parameter flattening, tensor counting, and state-dict load simulation.

## Overview
- Regression and behavior checks run by the LeanTest-based test suite.
- Uses markdown module docs so `doc-gen4` renders a readable module landing section.
-/

open torch
open torch.moddedGpt

/-- Helper to flatten model to a list of tensors -/
def flattenModel [TensorStruct α] (model : α) : List (Σ s, T s) :=
  TensorStruct.fold (fun {s} t acc => (⟨s, t⟩ : Σ s, T s) :: acc) [] model |>.reverse

/-- Helper to count elements in flattened model -/
def countElements (flat : List (Σ s, T s)) : Nat :=
  flat.foldl (fun acc ⟨s, _⟩ => acc + s.foldl (fun p d => p * d.toNat) 1) 0

@[test]
def testModdedGPTStructure : IO Unit := do
  -- Create tiny config
  let cfg : moddedGpt.Config := {
    vocabSize := 128
    nLayer := 2
    nHead := 2
    headDim := 16
    modelDim := 32
    maxSeqLen := 64
    blockSize := 32
    numValueEmbeds := 1
  }

  -- Init model
  let params ← ModdedGPTParams.init cfg

  -- Flatten
  let flat := flattenModel params
  
  -- Verify count
  -- 1. embed: 1
  -- 2. smearGate.weight: 1
  -- 3. valueEmbeds[0]: 1
  -- blocks (2 layers, each has attn + mlp):
  --   4-7. blocks[0].attn (wQ, wK, wV, wO): 4
  --   8-9. blocks[0].mlp (cFc, cProj): 2
  --   10-13. blocks[1].attn: 4
  --   14-15. blocks[1].mlp: 2
  -- 16. lmHead.weight: 1
  -- 17. scalars.values: 1
  -- Total: 1 + 1 + 1 + 6 + 6 + 1 + 1 = 17
  let numTensors := flat.length
  LeanTest.assertEqual numTensors 17 "Should have 17 tensors in the model structure"

  -- Verify total elements
  let totalElems := countElements flat
  LeanTest.assertTrue (totalElems > 0) "Total elements should be positive"

@[test]
def testParameterUpdate : IO Unit := do
  -- Verify we can map over parameters to update them (simulating optimizer step or loading)
  let cfg : moddedGpt.Config := {
    vocabSize := 10
    nLayer := 1
    nHead := 1
    headDim := 4
    modelDim := 4
    maxSeqLen := 10
    blockSize := 10
    numValueEmbeds := 1
  }
  
  let params ← ModdedGPTParams.init cfg
  
  -- Apply update: p = p + 1
  let updatedParams := TensorStruct.map (fun t => t + (1.0 : Float)) params
  
  -- Check one tensor to verify update
  let embedSumOriginal := nn.item (nn.sumAll params.embed)
  let embedSumUpdated := nn.item (nn.sumAll updatedParams.embed)
  
  let diff := embedSumUpdated - embedSumOriginal
  let expectedDiff := (cfg.vocabSize * cfg.modelDim).toFloat -- adding 1.0 to each element
  
  LeanTest.assertTrue (Float.abs (diff - expectedDiff) < 1e-4) "Parameters should be updated"

@[test]
unsafe def testStateDictSimulation : IO Unit := do
  -- Simulate saving to a state dict (list of tensors) and loading back
  let cfg : moddedGpt.Config := {
    vocabSize := 10
    nLayer := 1
    nHead := 1
    headDim := 4
    modelDim := 4
    maxSeqLen := 10
    blockSize := 10
    numValueEmbeds := 1
  }
  
  let params ← ModdedGPTParams.init cfg
  
  -- "Save" to list
  let stateList := flattenModel params
  
  -- "Load" from list (Mock implementation of loading logic)
  -- We use mapM with a stateful iterator to consume the list
  let loadFromList (list : List (Σ s, T s)) (model : ModdedGPTParams cfg) 
      : IO (ModdedGPTParams cfg) := do
    let ref ← IO.mkRef list
    TensorStruct.mapM (fun {s} _oldT => do
      let remaining ← ref.get
      match remaining with
      | [] => throw $ IO.userError "Not enough tensors in state list"
      | ⟨_s', t⟩ :: rest => 
        -- In real loading, we'd check shape match here (s == s')
        -- But T s and T s' are different types if s != s' statically
        -- We cast or rely on runtime check
        ref.set rest
        -- Unsafe cast for this test since we know shapes match
        -- In real code, we'd load by name or validate shape
        pure (unsafeCast t : T s)
    ) model

  let loadedParams ← loadFromList stateList params
  
  -- Verify loaded matches original
  let diff := TensorStruct.zipWith (fun a b => a - b) params loadedParams
  let totalDiff := TensorStruct.fold (fun {_s} t acc => acc + nn.item (nn.sumAll (nn.abs t))) 0.0 diff
  
  LeanTest.assertTrue (totalDiff < 1e-6) "Loaded parameters should match saved ones"
