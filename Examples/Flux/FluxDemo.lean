/-
  Examples/Flux/FluxDemo.lean

  End-to-end demonstration of Flux Klein 4B image generation.
  Shows complete pipeline: text encoding → diffusion → VAE decoding.
-/
import Tyr.Torch
import Tyr.Model.Qwen
import Tyr.Model.Qwen.Weights
import Tyr.Model.VAE
import Tyr.Model.VAE.Weights
import Tyr.Model.Flux
import Tyr.Model.Flux.Weights
import Tyr.Tokenizer.Qwen3

namespace Examples.Flux

open torch
open torch.qwen
open torch.vae
open torch.flux

private def toFloat32 {α : Type} [TensorStruct α] (x : α) : α :=
  TensorStruct.map toFloat' x

private def toFloat32Embedder {cfg : QwenConfig} {max_seq : UInt64}
    (e : QwenFluxEmbedder cfg max_seq) : QwenFluxEmbedder cfg max_seq :=
  { e with model := toFloat32 e.model }

/-- Configuration for the demo -/
structure DemoConfig where
  /-- Directory containing sharded Qwen text encoder weights -/
  qwenDir : String := "weights/flux-klein-4b/text_encoder"
  /-- Path to Flux Klein 4B SafeTensors weights (single file) -/
  fluxPath : String := "weights/flux.safetensors"
  /-- Path to VAE SafeTensors weights (single file) -/
  vaePath : String := "weights/ae.safetensors"
  /-- Output image path -/
  outputPath : String := "output.ppm"
  /-- Whether to load tokens from files instead of generating them -/
  useTokenFiles : Bool := false
  /-- Optional token file (whitespace-separated token IDs) -/
  tokensPath : String := "weights/flux-klein-4b/tokenizer/tokens.txt"
  /-- Optional attention mask file (whitespace-separated 0/1 IDs) -/
  attnMaskPath : String := "weights/flux-klein-4b/tokenizer/attention_mask.txt"
  /-- Number of diffusion steps -/
  numSteps : Nat := 4
  /-- Packed latent height (16 for 256x256 output with 2×2 patchification and 8× VAE upscaling) -/
  latentH : UInt64 := 16
  /-- Packed latent width (16 for 256x256 output with 2×2 patchification and 8× VAE upscaling) -/
  latentW : UInt64 := 16
  deriving Repr, Inhabited

private def qwenPadId : Int64 := 151643
private def maxSeqLen : UInt64 := 512

private def parseTokenIds (content : String) : Array Int64 := Id.run do
  let mut out : Array Int64 := #[]
  let mut cur : String := ""
  for c in content.toList do
    if c.isDigit then
      cur := cur.push c
    else
      if !cur.isEmpty then
        match cur.toNat? with
        | some n => out := out.push n.toInt64
        | none => pure ()
        cur := ""
  if !cur.isEmpty then
    match cur.toNat? with
    | some n => out := out.push n.toInt64
    | none => pure ()
  out

private def padTokens (ids : Array Int64) (maxLen : UInt64) (padId : Int64)
    : Array Int64 × Array Int64 := Id.run do
  let max := maxLen.toNat
  let mut tokens : Array Int64 := Array.mkEmpty max
  let mut mask : Array Int64 := Array.mkEmpty max
  for i in [:max] do
    if h : i < ids.size then
      tokens := tokens.push (ids[i]'h)
      mask := mask.push (1 : Int64)
    else
      tokens := tokens.push padId
      mask := mask.push (0 : Int64)
  (tokens, mask)

private def loadTokenIds (path : String) (maxLen : UInt64) : IO (Array Int64) := do
  let contents ← IO.FS.readFile path
  let mut ids := parseTokenIds contents
  if ids.isEmpty then
    throw (IO.userError s!"No tokens found in {path}")
  if ids.size.toUInt64 > maxLen then
    IO.println s!"    Truncating tokens from {ids.size} to {maxLen}"
    ids := ids.extract 0 maxLen.toNat
  pure ids

private def loadMaskIds (path : String) (maxLen : UInt64) : IO (Array Int64) := do
  let contents ← IO.FS.readFile path
  let mut ids := parseTokenIds contents
  if ids.isEmpty then
    throw (IO.userError s!"No mask values found in {path}")
  if ids.size.toUInt64 > maxLen then
    IO.println s!"    Truncating mask from {ids.size} to {maxLen}"
    ids := ids.extract 0 maxLen.toNat
  if ids.size.toUInt64 < maxLen then
    let mut padded : Array Int64 := Array.mkEmpty maxLen.toNat
    for i in [:maxLen.toNat] do
      if h : i < ids.size then
        padded := padded.push (ids[i]'h)
      else
        padded := padded.push (0 : Int64)
    ids := padded
  pure ids

/-- Main demo: generate an image from a text prompt -/
def runDemo (cfg : DemoConfig) (prompt : String) : IO Unit := do
  IO.println "=== Flux Klein 4B Demo ==="

  IO.println s!"Prompt: {prompt}"
  IO.println ""

  -- Load models
  IO.println "Loading models..."

  -- Load Qwen text encoder (sharded, with Flux Klein config)
  let qwenCfg := QwenConfig.fluxKleinTextEncoder
  let qwen ← loadQwenFluxEmbedderSharded cfg.qwenDir qwenCfg maxSeqLen #[8, 17, 26]
  let qwen := toFloat32Embedder qwen
  IO.println "  ✓ Qwen text encoder loaded (Flux Klein variant)"

  -- Load Flux model
  let fluxCfg := FluxConfig.klein4B
  let flux ← loadFluxModel cfg.fluxPath fluxCfg
  let flux := toFloat32 flux
  IO.println "  ✓ Flux model loaded"

  -- Load VAE AutoEncoder (includes BN stats for proper normalization)
  let vae ← loadAutoEncoder cfg.vaePath
  let vae := toFloat32 vae
  IO.println "  ✓ VAE AutoEncoder loaded"

  IO.println ""
  IO.println "Generating image..."

  -- Step 1: Tokenize and encode text
  IO.println "  [1/4] Encoding text..."
  let (tokens, attnMask, tokenCount) ←
    if cfg.useTokenFiles then
      if !(← data.fileExists cfg.tokensPath) then
        throw (IO.userError s!"Token file not found: {cfg.tokensPath}")
      IO.println s!"    Loading tokens from {cfg.tokensPath}"
      let ids ← loadTokenIds cfg.tokensPath maxSeqLen
      let tokenCount := ids.size.toUInt64
      let (padded, defaultMask) := padTokens ids maxSeqLen qwenPadId
      let mask ←
        if (← data.fileExists cfg.attnMaskPath) then
          IO.println s!"    Loading attention mask from {cfg.attnMaskPath}"
          loadMaskIds cfg.attnMaskPath maxSeqLen
        else
          pure defaultMask
      let tokens := reshape (data.fromInt64Array padded) #[1, maxSeqLen]
      let attnMask := reshape (data.fromInt64Array mask) #[1, maxSeqLen]
      pure (tokens, attnMask, tokenCount)
    else
      let tok ← tokenizer.qwen3.loadTokenizer cfg.qwenDir
      let (tokIds, maskIds) := tokenizer.qwen3.encodePrompt tok prompt maxSeqLen.toNat
      let tokenCount := maskIds.foldl (fun acc v => if v != 0 then acc + 1 else acc) (0 : UInt64)
      let tokens := reshape (data.fromInt64Array (tokenizer.qwen3.toInt64Array tokIds)) #[1, maxSeqLen]
      let attnMask := reshape (data.fromInt64Array (tokenizer.qwen3.toInt64Array maskIds)) #[1, maxSeqLen]
      pure (tokens, attnMask, tokenCount)

  let txtEmb := qwen.encodeMasked qwenCfg maxSeqLen tokens attnMask
  IO.println s!"    Text token count: {tokenCount}"
  IO.println s!"    Text embedding shape: {txtEmb.runtimeShape}"
  IO.println s!"    Text embedding dtype: {txtEmb.dtype}"

  -- Step 2: Prepare latent space
  IO.println "  [2/4] Preparing latent space..."
  let imgSeq := cfg.latentH * cfg.latentW
  let noiseSpatial ← torch.randn #[1, 128, cfg.latentH, cfg.latentW]
  let noiseSeq := permute noiseSpatial #[0, 2, 3, 1]
  let noise : T #[1, imgSeq, 128] := reshape noiseSeq #[1, imgSeq, 128]

  -- Compute position IDs for RoPE
  let imgIds ← computeImagePositionIds cfg.latentH cfg.latentW
  let txtIds ← computeTextPositionIds maxSeqLen

  -- Step 3: Run diffusion denoising
  IO.println "  [3/4] Running Flux denoising..."
  let latents := denoise fluxCfg flux noise txtEmb imgIds txtIds cfg.numSteps
  IO.println s!"    Denoised with {cfg.numSteps} steps"
  -- Transform latents for VAE (inverse of flattening)
  let latentsHW : T #[1, cfg.latentH, cfg.latentW, 128] :=
    reshape latents #[1, cfg.latentH, cfg.latentW, 128]
  let packedLatents : T #[1, 128, cfg.latentH, cfg.latentW] :=
    permute latentsHW #[0, 3, 1, 2]

  -- Step 4: Decode with VAE and save
  IO.println "  [4/4] Decoding with VAE..."

  -- Run VAE decode pipeline
  let z := vae.invNormalize packedLatents
  let z := torch.vae.AutoEncoder.unpackLatents16x16 z
  let image := vae.decoder.forward1 z
  torch.data.savePPMExplicit #[1, 3, 256, 256] image cfg.outputPath
  IO.println s!"  ✓ Image saved to {cfg.outputPath}"


/-- Main entry point -/
def _root_.main (args : List String) : IO UInt32 := do
  let prompt := match args with
    | arg :: _ => arg
    | [] => "a cat sitting on a windowsill, photorealistic"

  let cfg : DemoConfig := {
    qwenDir := "weights/flux-klein-4b/text_encoder"
    fluxPath := "weights/flux.safetensors"
    vaePath := "weights/ae.safetensors"
    outputPath := "output.ppm"
    useTokenFiles := false
    tokensPath := "weights/flux-klein-4b/tokenizer/tokens.txt"
    attnMaskPath := "weights/flux-klein-4b/tokenizer/attention_mask.txt"
    numSteps := 4
    latentH := 16
    latentW := 16
  }

  runDemo cfg prompt
  return 0

end Examples.Flux
